{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95e0b45a-1ba2-45e0-9cc8-ce9e69b2f72a",
   "metadata": {
    "collapsed": false,
    "name": "cell19"
   },
   "source": [
    "# 1. Objective\n",
    "  The Objective of the notebook is to generate new features (from the raw data) based on the provided inputs in the config. The notebook helps us to create the following types of features\n",
    "  * Lag / Lead features\n",
    "  * Log transformed features\n",
    "  * Trend features\n",
    "  * Seasonality features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec757b30-b22a-423a-8d3c-ba4e04217a06",
   "metadata": {
    "collapsed": false,
    "name": "cell13"
   },
   "source": [
    "# 2. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c983fc2-950b-41c6-be81-726f32af7abb",
   "metadata": {
    "language": "python",
    "name": "cell94"
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import traceback\n",
    "import shutil\n",
    "import yaml\n",
    "\n",
    "# --- Snowpark Imports ---\n",
    "from snowflake.snowpark.context import get_active_session\n",
    "from snowflake.snowpark import functions as F\n",
    "from snowflake.snowpark.functions import col\n",
    "from snowflake.snowpark.window import Window\n",
    "from snowflake.snowpark.types import *\n",
    "\n",
    "# ======================================================\n",
    "# Initialize Snowpark Session\n",
    "# ======================================================\n",
    "\n",
    "# If running inside Snowflake (e.g., Snowflake Worksheet, Snowsight, or Streamlit for Snowflake)\n",
    "session = get_active_session()\n",
    "\n",
    "# If running locally, uncomment and configure connection details:\n",
    "\n",
    "# ======================================================\n",
    "# Snowpark is now ready to use (Equivalent to SparkSession)\n",
    "# ======================================================\n",
    "\n",
    "# Example check (optional)\n",
    "print(\"✅ Snowpark Session Initialized Successfully!\")\n",
    "print(\"Current Database:\", session.get_current_database())\n",
    "print(\"Current Schema:\", session.get_current_schema())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834239b6-4532-4de6-ba31-f039d91f267e",
   "metadata": {
    "collapsed": false,
    "name": "cell20"
   },
   "source": [
    "# 3. Setup environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2908be-b04d-402a-b5d6-19491d79c507",
   "metadata": {
    "collapsed": false,
    "name": "cell11"
   },
   "source": [
    "## 3.1. Load Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88fbf34c-d6f2-4b2d-9955-a9f03dde2a06",
   "metadata": {
    "language": "python",
    "name": "cell95"
   },
   "outputs": [],
   "source": [
    "import yaml\n",
    "stage_path = \"@ORANGE_ZONE_SBX_TA.PUBLIC.CONNECTIONS/config_new_PROD.yaml\"\n",
    "stream = session.file.get_stream(stage_path)\n",
    "yaml_text = stream.read().decode()\n",
    "app_config = yaml.safe_load(yaml_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdfb73ad-f21f-4a7b-bfd8-2253537f0b71",
   "metadata": {
    "collapsed": false,
    "name": "cell10"
   },
   "source": [
    "## 3.2 Update Output Database, Schema , table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c8c76c-a142-433e-b5a3-0b1d961a3c57",
   "metadata": {
    "language": "python",
    "name": "cell5"
   },
   "outputs": [],
   "source": [
    "output_database = app_config[\"general_inputs\"][\"output_database\"]\n",
    "output_schema = app_config[\"general_inputs\"][\"output_schema\"]\n",
    "print(output_database, output_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f421304f-e043-4d29-809c-c976f377aa88",
   "metadata": {
    "language": "python",
    "name": "cell6"
   },
   "outputs": [],
   "source": [
    "session.use_database(output_database)\n",
    "session.use_schema(output_schema)\n",
    "output_table_name = \"PROD_FEATURE_ENGINEERING_OUTPUT\"\n",
    "intermediate_table_name = \"PROD_FEATURE_ENGINEERING_INTERMEDIATE_RESULTS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38bea632-bcd8-4d63-83f9-c713a3936412",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "cell8"
   },
   "outputs": [],
   "source": [
    "# Example check (optional)\n",
    "print(\"✅ Snowpark Session Initialized Successfully!\")\n",
    "print(\"Current Database:\", session.get_current_database())\n",
    "print(\"Current Schema:\", session.get_current_schema())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce110000-1111-2222-3333-ffffff000011",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eaf4eabd-b53a-4e05-98fd-9d9a7f42d9f5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "collapsed": false,
    "name": "cell12"
   },
   "source": [
    "## 3.3. Capturing necessary variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e091be2-8f3f-4ed1-9839-06646ea96477",
   "metadata": {
    "language": "python",
    "name": "cell4"
   },
   "outputs": [],
   "source": [
    "date_variable = app_config[\"general_inputs\"][\"date_var\"]\n",
    "date_format = app_config[\"general_inputs\"][\"date_format_pyspark\"]\n",
    "date_format_pandas = app_config[\"general_inputs\"][\"date_format_pandas\"]\n",
    "\n",
    "ds_config = app_config[\"general_inputs\"][\"date_var\"]\n",
    "modeling_granularity = app_config[\"general_inputs\"][\"modeling_granularity\"]\n",
    "\n",
    "categorical_columns_ads = app_config[\"feature_engineering_details\"][\"categorical_columns_ads\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c67e36-fee6-436c-8469-ee63766dfb7e",
   "metadata": {
    "collapsed": false,
    "name": "cell9"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ce110000-1111-2222-3333-ffffff000013",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3bca9a1a-ceda-46dc-a3df-ea8105b76da4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "collapsed": false,
    "name": "cell14"
   },
   "source": [
    "# Function to broadcast variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "id": "ce110000-1111-2222-3333-ffffff000014",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ab0dc5db-c8ba-4377-acb4-6c7702cfaa86",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "language": "python",
    "name": "cell15"
   },
   "outputs": [],
   "source": [
    "def broadcast_variable_conf(x):\n",
    "    \"\"\"\n",
    "    In Snowpark, there's no need for Spark-style broadcast variables.\n",
    "    This function simply returns the variable directly,\n",
    "    as Snowflake automatically optimizes variable usage in UDFs and queries.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : any\n",
    "        Configuration variables or constants.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict or any\n",
    "        The same configuration object (no broadcasting needed).\n",
    "    \"\"\"\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce110000-1111-2222-3333-ffffff000015",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b3fa1a4c-4240-47d8-bc9a-7b650cd51488",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "collapsed": false,
    "name": "cell16"
   },
   "source": [
    "# Broadcast generic parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "id": "ce110000-1111-2222-3333-ffffff000016",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1619c9ea-5197-4212-a885-40c85cfcbadd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "language": "python",
    "name": "cell17"
   },
   "outputs": [],
   "source": [
    "broadcast_date_variable = broadcast_variable_conf(date_variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce110000-1111-2222-3333-ffffff000017",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7e9ac8b3-f6d2-4861-9640-03bc9c864122",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "collapsed": false,
    "name": "cell18"
   },
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487dd99c-fc05-4d50-8f21-730052a59324",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "cell97"
   },
   "outputs": [],
   "source": [
    "df = session.table(\"PROD_MISSING_VALUE_TREATMENT_OUTPUT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362734c0-2ea0-48f1-a6e5-9e4766e01fc0",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "cell120"
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3dace4-df4c-490c-adac-2a2149f3b16e",
   "metadata": {
    "language": "python",
    "name": "cell121"
   },
   "outputs": [],
   "source": [
    "#from snowflake.snowpark.functions import col, to_date, lit\n",
    "\n",
    "date_col = app_config[\"general_inputs\"][\"date_var\"]\n",
    "\n",
    "# Convert to date (Snowflake handles parsing; invalid → NULL automatically)\n",
    "df = df.with_column(\n",
    "    date_col,\n",
    "    F.to_date(F.col(date_col))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee142e5-66db-4923-8726-fb7bbdebef16",
   "metadata": {
    "language": "python",
    "name": "cell122"
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce110000-1111-2222-3333-ffffff000022",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3d2fecde-f35f-45df-a75d-c420d7136c1e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "collapsed": false,
    "name": "cell23"
   },
   "source": [
    "# Metrics calculated at modeling_granularity level (within timeseries)\n",
    "  The following metrics are calculated for each unique combination of `modeling_granularity` using the historical data available in a parallelized execution.\n",
    "  1. Lag/Lead features\n",
    "  2. Log Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce110000-1111-2222-3333-ffffff000030",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7c0b6825-0f86-407f-8670-3efdf26ea9b3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "collapsed": false,
    "name": "cell31"
   },
   "source": [
    "## 1. Feature Lag/Lead Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce110000-1111-2222-3333-ffffff000031",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ade1b070-cf70-479a-b645-4c225ced256a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "collapsed": false,
    "name": "cell32"
   },
   "source": [
    "### 1.1. Config parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5d600f-1657-4dba-b650-eb126d72d81c",
   "metadata": {
    "language": "python",
    "name": "cell102"
   },
   "outputs": [],
   "source": [
    "featurewise_lag_lead_dict = {}\n",
    "\n",
    "for feature, lag_lead_value in app_config[\"feature_engineering_details\"][\"featurewise_lag_lead_dict\"].items():\n",
    "    try:\n",
    "        # unpack safely\n",
    "        lag_or_lead = lag_lead_value[0]\n",
    "        offsets = lag_lead_value[1] if len(lag_lead_value) > 1 else []\n",
    "        freq = lag_lead_value[2] if len(lag_lead_value) > 2 else \"unknown\"\n",
    "\n",
    "        if lag_or_lead == \"lag\":\n",
    "            featurewise_lag_lead_dict[feature] = [offsets, freq]\n",
    "        else:\n",
    "            featurewise_lag_lead_dict[feature] = [[-i for i in offsets], freq]\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Error processing {feature}: {lag_lead_value} — {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "id": "ce110000-1111-2222-3333-ffffff000032",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "32216d6c-7676-4100-b24f-60732d7b7b88",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "codeCollapsed": false,
    "language": "python",
    "name": "cell33"
   },
   "outputs": [],
   "source": [
    "lag_lead_needed = app_config[\"feature_engineering_details\"][\"lag_lead_needed\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0de7255-541a-4be9-8ed6-d5fcf7683419",
   "metadata": {
    "language": "python",
    "name": "cell24"
   },
   "outputs": [],
   "source": [
    "lag_lead_needed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce110000-1111-2222-3333-ffffff000033",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5775273c-7b8b-43b5-b06a-1a04841d729b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "collapsed": false,
    "name": "cell34"
   },
   "source": [
    "### 1.2. Broadcast variables for use in lag/lead creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "id": "ce110000-1111-2222-3333-ffffff000034",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "abeffdb8-7394-44d6-8484-71656a98f5ae",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "language": "python",
    "name": "cell35"
   },
   "outputs": [],
   "source": [
    "broadcast_lag_lead_needed = broadcast_variable_conf(lag_lead_needed)\n",
    "broadcast_featurewise_lag_lead_dict = broadcast_variable_conf(featurewise_lag_lead_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454e6160-4610-4705-a6ba-7dfddd713fdd",
   "metadata": {
    "language": "python",
    "name": "cell2"
   },
   "outputs": [],
   "source": [
    "lag_cols = []\n",
    "for feature, (shift_value, fill_value) in broadcast_featurewise_lag_lead_dict.items():\n",
    "        for cur_shift_val in shift_value:\n",
    "            if cur_shift_val > 0:\n",
    "                lag_cols.append(f'{feature}_LAG{cur_shift_val}')\n",
    "            else:\n",
    "                lag_cols.append(f'{feature}_LEAD{cur_shift_val}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce110000-1111-2222-3333-ffffff000035",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8500c8e3-32ab-4510-8ad6-b73bcaa5e698",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "collapsed": false,
    "name": "cell36"
   },
   "source": [
    "### 1.3. API for Lag/Lead creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "id": "ce110000-1111-2222-3333-ffffff000036",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5937b041-027b-419e-b591-d29218452c3b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "language": "python",
    "name": "cell37"
   },
   "outputs": [],
   "source": [
    "def create_featurewise_lag_lead_versions(\n",
    "    df: pd.DataFrame,\n",
    "    featurewise_lag_lead_dict: dict,\n",
    ") -> pd.DataFrame:\n",
    "    for feature, (shift_value, fill_value) in featurewise_lag_lead_dict.items():\n",
    "        for cur_shift_val in shift_value:\n",
    "            if cur_shift_val > 0:\n",
    "                df[f'{feature}_LAG{cur_shift_val}'] = df[feature].shift(cur_shift_val, fill_value=fill_value)\n",
    "            else:\n",
    "                df[f'{feature}_LEAD{cur_shift_val}'] = df[feature].shift(cur_shift_val, fill_value=fill_value)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce110000-1111-2222-3333-ffffff000037",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "146a2359-13e4-4bf1-84b2-4e5b2139914d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "collapsed": false,
    "name": "cell38"
   },
   "source": [
    "## 2. Log-transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce110000-1111-2222-3333-ffffff000038",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c2031b93-267d-4082-a66c-7cfc32e6d1f5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "collapsed": false,
    "name": "cell39"
   },
   "source": [
    "### 2.1. Config parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "id": "ce110000-1111-2222-3333-ffffff000039",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "21918979-50c9-4b62-84f4-9746e2b40ddf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "language": "python",
    "name": "cell40"
   },
   "outputs": [],
   "source": [
    "log_transformation_needed = app_config[\"feature_engineering_details\"][\"log_transformation_needed\"]\n",
    "\n",
    "log_transformation_features = app_config[\"feature_engineering_details\"][\"log_transformation_features\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce110000-1111-2222-3333-ffffff000040",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "03cbce77-f3ba-42c8-8cb5-97f24e38558f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "collapsed": false,
    "name": "cell41"
   },
   "source": [
    "### 2.2. Broadcast variables for use in log-transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "id": "ce110000-1111-2222-3333-ffffff000041",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "99b43a80-0e2d-405a-9a36-92578b5fbcfb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "language": "python",
    "name": "cell42"
   },
   "outputs": [],
   "source": [
    "broadcast_log_transformation_needed = broadcast_variable_conf(log_transformation_needed)\n",
    "broadcast_log_transformation_features = broadcast_variable_conf(log_transformation_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ade32be-ae34-4375-b9dc-0a10a55b8351",
   "metadata": {
    "language": "python",
    "name": "cell1"
   },
   "outputs": [],
   "source": [
    "log_cols = broadcast_log_transformation_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce110000-1111-2222-3333-ffffff000042",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7a87eb6d-b8f7-4773-85f8-3780fa4fb275",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "collapsed": false,
    "name": "cell43"
   },
   "source": [
    "### 2.3. API for log-transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "id": "ce110000-1111-2222-3333-ffffff000043",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4e417feb-adad-41a2-af26-b8b75bfd035d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "language": "python",
    "name": "cell44"
   },
   "outputs": [],
   "source": [
    "def create_log_transformed_features(\n",
    "    df: pd.DataFrame,\n",
    "    features: list[str],\n",
    ") -> pd.DataFrame:\n",
    "    for feature in features:\n",
    "        if (df[feature] < 0).any():\n",
    "            raise ValueError(f'{feature} has negative values; log-transformation requires all positive.')\n",
    "        else:\n",
    "            df[f'LOG_{feature}'] = np.log1p(df[feature])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe068ec-c496-4c84-bf7c-8cf1adf1477d",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "cell133"
   },
   "outputs": [],
   "source": [
    "lag_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "id": "ce110000-1111-2222-3333-ffffff000055",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b483e364-6124-4517-8a23-d93220d5080c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "codeCollapsed": false,
    "language": "python",
    "name": "cell56"
   },
   "outputs": [],
   "source": [
    "def feat_udf(udf_input_data: pd.DataFrame) -> pd.DataFrame:   \n",
    "    try:\n",
    "        udf_output_data = udf_input_data.copy()\n",
    "\n",
    "        # Get the parameter values from the broadcasted variables\n",
    "        date_column = broadcast_date_variable\n",
    "\n",
    "        # Lag/Lead transformations\n",
    "        if broadcast_lag_lead_needed:\n",
    "            udf_output_data = create_featurewise_lag_lead_versions(\n",
    "                df=udf_output_data,\n",
    "                featurewise_lag_lead_dict=broadcast_featurewise_lag_lead_dict,\n",
    "            )\n",
    "\n",
    "        # Log transformations\n",
    "        if broadcast_log_transformation_needed:\n",
    "            udf_output_data = create_log_transformed_features(\n",
    "                df=udf_output_data,\n",
    "                features=broadcast_log_transformation_features,\n",
    "            )\n",
    "\n",
    "        lag_cols = []\n",
    "        for feature, (shift_value, fill_value) in broadcast_featurewise_lag_lead_dict.items():\n",
    "                for cur_shift_val in shift_value:\n",
    "                    if cur_shift_val > 0:\n",
    "                        lag_cols.append(f'{feature}_LAG{cur_shift_val}')\n",
    "                    else:\n",
    "                        lag_cols.append(f'{feature}_LEAD{cur_shift_val}')\n",
    "        req_cols = modeling_granularity + [date_col]  + lag_cols + [\"LOG_\"+i for i in broadcast_log_transformation_features] + [\"status\"]\n",
    "        udf_output_data[\"status\"] = \"success\"\n",
    "        return udf_output_data[req_cols]\n",
    "    \n",
    "    except Exception as e:\n",
    "        udf_output_data = udf_input_data.copy()\n",
    "        \n",
    "        if broadcast_lag_lead_needed:\n",
    "            lag_lead_columns = [\n",
    "                    f'{feature}_LAG{shift_value}' if shift_value > 0\n",
    "                    else f'{feature}_LEAD{shift_value}' for feature, (shift_list, _) in broadcast_featurewise_lag_lead_dict.items() for shift_value in shift_list\n",
    "            ]\n",
    "            udf_output_data[lag_lead_columns] = -1.0\n",
    "        \n",
    "        if broadcast_log_transformation_needed:\n",
    "            log_transformation_columns = [\n",
    "                f'LOG_{feature}' for feature in broadcast_log_transformation_features\n",
    "            ]\n",
    "            udf_output_data[log_transformation_columns] = -1.0\n",
    "    \n",
    "        lag_cols = []\n",
    "        for feature, (shift_value, fill_value) in broadcast_featurewise_lag_lead_dict.items():\n",
    "                for cur_shift_val in shift_value:\n",
    "                    if cur_shift_val > 0:\n",
    "                        lag_cols.append(f'{feature}_LAG{cur_shift_val}')\n",
    "                    else:\n",
    "                        lag_cols.append(f'{feature}_LEAD{cur_shift_val}')\n",
    "        req_cols = modeling_granularity + [date_col]  + lag_cols + [\"LOG_\"+i for i in broadcast_log_transformation_features] + [\"status\"]\n",
    "\n",
    "        udf_output_data[\"status\"] = str(traceback.format_exc()) \n",
    "        \n",
    "        return udf_output_data[req_cols]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce110000-1111-2222-3333-ffffff000056",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ad7dc2f6-6e2b-48e4-87dd-47cb11312555",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "collapsed": false,
    "name": "cell57"
   },
   "source": [
    "### 5.2. Schema of the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8dbd19-3236-4423-af8e-b6d4dd59bcf3",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "cell103"
   },
   "outputs": [],
   "source": [
    "input_data = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "id": "ce110000-1111-2222-3333-ffffff000057",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aefca046-88f7-4ac4-b390-5546b96dba72",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "codeCollapsed": false,
    "language": "python",
    "name": "cell58"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "input_data_schema = [StructField(x,StringType()) for x in modeling_granularity] + [StructField(x,DateType()) for x in [date_col]]\n",
    "output_data_schema = [] + input_data_schema\n",
    "\n",
    "if lag_lead_needed:\n",
    "\n",
    "    lag_lead_columns = [\n",
    "            [f'{feature}_lag{cur_shift}' if cur_shift > 0 else f'{feature}_lead{cur_shift}' for cur_shift in shift_value]\n",
    "            for feature, (shift_value, _) in featurewise_lag_lead_dict.items()\n",
    "    ]\n",
    "    print(lag_lead_columns)\n",
    "    final_lead_lag_cols = []\n",
    "    if len(lag_lead_columns)>1:\n",
    "        #lag_lead_columns = lag_lead_columns[0] + lag_lead_columns[1]\n",
    "        final_lead_lag_cols = [item for sublist in lag_lead_columns for item in sublist]\n",
    "    # else:\n",
    "    #     lag_lead_columns = lag_lead_columns[0]\n",
    "    lag_lead_columns_schema = [StructField(x.replace(\"-\",\"\"),FloatType()) for x in final_lead_lag_cols]\n",
    "    output_data_schema = output_data_schema + lag_lead_columns_schema\n",
    "\n",
    "if log_transformation_needed:\n",
    "    log_transformation_columns = [\n",
    "        f'log_{feature}' for feature in log_transformation_features\n",
    "    ]\n",
    "    log_transformation_columns_schema = [StructField(x,FloatType()) for x in log_transformation_columns]\n",
    "    output_data_schema = output_data_schema + log_transformation_columns_schema\n",
    "\n",
    "output_data_schema = output_data_schema + [StructField(\"status\", StringType())]\n",
    "output_data_schema = StructType(output_data_schema)\n",
    "\n",
    "print(output_data_schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce110000-1111-2222-3333-ffffff000059",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0d15afbe-849f-4549-afd9-52d60ae20dc2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "collapsed": false,
    "name": "cell60"
   },
   "source": [
    "### 5.3. Apply UDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce110000-1111-2222-3333-ffffff000061",
   "metadata": {
    "collapsed": false,
    "name": "cell62"
   },
   "source": [
    "# Testing the UDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7bbf16f-c42d-495f-aa93-4794cf4c4ef3",
   "metadata": {
    "language": "python",
    "name": "cell104"
   },
   "outputs": [],
   "source": [
    "t_df = input_data.to_pandas()\n",
    "t_df = t_df[t_df[\"F_CODE\"] == \"0307\"]\n",
    "print(t_df.shape)\n",
    "feat_udf(t_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb515c65-c28a-4028-8ea6-69cf7e761685",
   "metadata": {
    "language": "python",
    "name": "cell3"
   },
   "outputs": [],
   "source": [
    "raw_cols_lag = list(app_config[\"feature_engineering_details\"][\"featurewise_lag_lead_dict\"].keys())\n",
    "raw_cols_log = log_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27cb1ea8-3a6e-4cf6-b7a5-4235fa5375bd",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "cell131"
   },
   "outputs": [],
   "source": [
    "req_cols = modeling_granularity + [ds_config] + raw_cols_lag + raw_cols_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "id": "ce110000-1111-2222-3333-ffffff000062",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f769eea1-b828-4503-a075-b032afcb966c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "codeCollapsed": false,
    "language": "python",
    "name": "cell63"
   },
   "outputs": [],
   "source": [
    "feature_engineering_output = input_data.select(req_cols).groupBy(modeling_granularity).applyInPandas(feat_udf, output_schema=output_data_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "id": "ce110000-1111-2222-3333-ffffff000063",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a3f6b831-c6d8-4d14-95ff-f949a3c0eea4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "codeCollapsed": false,
    "language": "python",
    "name": "cell64"
   },
   "outputs": [],
   "source": [
    "feature_engineering_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "id": "ce110000-1111-2222-3333-ffffff000067",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "732a28e7-8283-443f-91b5-4c04ba3d189d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "language": "python",
    "name": "cell68"
   },
   "outputs": [],
   "source": [
    "feature_engineering_output.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "id": "ce110000-1111-2222-3333-ffffff000068",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8e686032-c8c0-4fc2-99b6-c294c4453382",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "codeCollapsed": false,
    "language": "python",
    "name": "cell69"
   },
   "outputs": [],
   "source": [
    "categorical_columns_ads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "id": "ce110000-1111-2222-3333-ffffff000070",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e1525d5a-a352-4831-bdf3-ae47a3f42b0c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "language": "python",
    "name": "cell71"
   },
   "outputs": [],
   "source": [
    "#feature_engineering_output.filter(F.col(\"status\")!=\"success\").display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "id": "ce110000-1111-2222-3333-ffffff000071",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "06b049f5-4684-41e6-a437-e26e588c118d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "language": "python",
    "name": "cell72"
   },
   "outputs": [],
   "source": [
    "list(feature_engineering_output.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce110000-1111-2222-3333-ffffff000072",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a03c1ddf-082b-44d5-9a70-f3b594eaadf4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "name": "cell73"
   },
   "source": [
    "### 5.5. Export intermediate results\n",
    "This is needed to break the lazy evaluation nature of Spark and store the intermediate results and read later on to speeden up the downstream tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a423b9f-f247-47c0-8abb-c4180c55aece",
   "metadata": {
    "language": "python",
    "name": "cell135"
   },
   "outputs": [],
   "source": [
    "feature_engineering_output_all_cols = input_data.join(feature_engineering_output, on = [*modeling_granularity,date_col], how = \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baee4fb8-f516-473a-9ee1-24ac6b23a2bb",
   "metadata": {
    "language": "python",
    "name": "cell136"
   },
   "outputs": [],
   "source": [
    "feature_engineering_output_all_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4728a4c8-5b14-4104-bf61-54424c5cad83",
   "metadata": {
    "language": "python",
    "name": "cell137"
   },
   "outputs": [],
   "source": [
    "feature_engineering_output_all_cols.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70d4331-213b-42d4-9657-1c648b917932",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "cell7"
   },
   "outputs": [],
   "source": [
    "# # write_file(pos, algo_path, \"/Pos_standardization_results (\")\n",
    "results_s_with_ts = feature_engineering_output_all_cols.with_column(\"LOAD_TS\", F.current_timestamp())\n",
    "results_s_with_ts.write.mode(\"overwrite\").save_as_table(intermediate_table_name)\n",
    "print(results_s_with_ts.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bcbe16b-2593-4a07-998c-5ddf29c920f2",
   "metadata": {
    "language": "python",
    "name": "cell127"
   },
   "outputs": [],
   "source": [
    "test_df = session.table(intermediate_table_name)\n",
    "print(\"All data ->\", test_df.count())\n",
    "latest_ts = test_df.select(F.max(\"LOAD_TS\")).collect()[0][0]\n",
    "feature_engineering_output = test_df.filter(F.col(\"LOAD_TS\") == F.lit(latest_ts))\n",
    "print(\"Latest data ->\", feature_engineering_output.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce110000-1111-2222-3333-ffffff000075",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b9c846fa-f0a7-41b3-ab60-063cf94584c8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "collapsed": false,
    "name": "cell76"
   },
   "source": [
    "# Metrics calculated at higher levels (across timeseries)\n",
    " The following metrics are created at different hierarchical levels (or dimensions) in the data and then merged back into the granular data (`modeling_granularity` level). Eg - Brand level, Category level, etc\n",
    "  1. SI Weekly\n",
    "  2. SI Monthly\n",
    "  3. SI Quarterly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce110000-1111-2222-3333-ffffff000076",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "91be89b2-8c33-451a-ba38-9c091d76ee06",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "name": "cell77"
   },
   "source": [
    "## 1. Seasonality-index Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce110000-1111-2222-3333-ffffff000077",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "02da8ccc-8879-484d-b1be-f5a542672af5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "name": "cell78"
   },
   "source": [
    "### 1.1. Derive frequency of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba508434-e396-485f-a3f9-4be4b15ad63e",
   "metadata": {
    "language": "python",
    "name": "cell123"
   },
   "outputs": [],
   "source": [
    "# 1. Get distinct values from the date column into pandas\n",
    "date_col = date_variable\n",
    "\n",
    "date_column_content = (\n",
    "    input_data\n",
    "        .select(F.col(date_col))\n",
    "        .dropDuplicates()\n",
    "        .to_pandas()        # NOTE: .toPandas() → .to_pandas() in new Snowpark\n",
    ")\n",
    "\n",
    "# 2. Convert to pandas datetime\n",
    "date_column_content[date_col] = pd.to_datetime(\n",
    "    date_column_content[date_col], errors=\"coerce\"\n",
    ")\n",
    "\n",
    "# 3. Create a sorted pandas Series of unique dates\n",
    "history_dates = (\n",
    "    pd.Series(date_column_content[date_col].dropna().unique())\n",
    "      .sort_values(ignore_index=True)\n",
    ")\n",
    "\n",
    "# 4. Infer frequency from the last 3 dates\n",
    "frequency = pd.infer_freq(history_dates.tail(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ca95c0-0220-4005-9a94-fe5b395bf122",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "cell105"
   },
   "outputs": [],
   "source": [
    "frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f3057a-ecc5-42b8-bcef-aeb989416c55",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "cell107"
   },
   "outputs": [],
   "source": [
    "history_dates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce110000-1111-2222-3333-ffffff000079",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5a6895c1-64d4-4fc7-9046-3aff52d06ffc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "collapsed": false,
    "name": "cell80"
   },
   "source": [
    "### 1.2. Config parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8604e00b-fef4-4fad-9c1a-1d01d7837fcf",
   "metadata": {
    "language": "python",
    "name": "cell22"
   },
   "outputs": [],
   "source": [
    "app_config[\"feature_engineering_details\"][\"si_needed\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "id": "ce110000-1111-2222-3333-ffffff000080",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "77ca56f2-70ad-47f0-82e8-cc26ec7fa51c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "codeCollapsed": false,
    "language": "python",
    "name": "cell81"
   },
   "outputs": [],
   "source": [
    "si_needed = app_config[\"feature_engineering_details\"][\"si_needed\"]\n",
    "si_target_column = app_config[\"feature_engineering_details\"][\"si_target_column\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a252c9c-17dd-4ee0-b2e2-21e99699b3c7",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "cell109"
   },
   "outputs": [],
   "source": [
    "si_needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f5287e-62ff-437d-8fb8-bbe62674e7c7",
   "metadata": {
    "language": "python",
    "name": "cell108"
   },
   "outputs": [],
   "source": [
    "si_target_column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce110000-1111-2222-3333-ffffff000081",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "14c671f8-a9f6-4ba8-985b-e7956e742f53",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "name": "cell82"
   },
   "source": [
    "### 1.3. Broadcast variables for use in SI creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "id": "ce110000-1111-2222-3333-ffffff000082",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9fd467fb-198d-4f27-a003-7767c1f943a7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "language": "python",
    "name": "cell83"
   },
   "outputs": [],
   "source": [
    "broadcast_si_needed = broadcast_variable_conf(si_needed)\n",
    "broadcast_frequency = broadcast_variable_conf(frequency)\n",
    "broadcast_si_target_column = broadcast_variable_conf(si_target_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f686bacb-6c4e-42c2-b4e6-48566f05a233",
   "metadata": {
    "language": "python",
    "name": "cell112"
   },
   "outputs": [],
   "source": [
    "broadcast_si_target_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e629bd-281b-4049-8a24-e70dc1e68a2b",
   "metadata": {
    "language": "python",
    "name": "cell111"
   },
   "outputs": [],
   "source": [
    "broadcast_si_needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef611cea-39cf-4ec3-b121-13c085f616f3",
   "metadata": {
    "language": "python",
    "name": "cell110"
   },
   "outputs": [],
   "source": [
    "broadcast_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986febb2-2f87-45a8-8d26-660a4a96f82e",
   "metadata": {
    "language": "python",
    "name": "cell116"
   },
   "outputs": [],
   "source": [
    "app_config[\"general_inputs\"]['date_var']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce110000-1111-2222-3333-ffffff000083",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "66034dc3-ff63-4d04-824b-6758e60b70ed",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "name": "cell84"
   },
   "source": [
    "### 1.4. API for SI creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e2318d-3039-42ef-a825-b50c9f24c959",
   "metadata": {
    "language": "python",
    "name": "cell117"
   },
   "outputs": [],
   "source": [
    "def create_seasonality_index(df, coln, si_target_column, granularity:str=None):\n",
    "    \"\"\"\n",
    "    Calculate seasonality index (SI) for quantity based on the given DataFrame and configuration.\n",
    "    \"\"\"\n",
    "\n",
    "    quantity_var = \"NO_OF_NEW_JOINEES\"\n",
    "    \n",
    "    # Convert all columns to uppercase\n",
    "    df = df.toDF(*[c.upper() for c in df.columns])\n",
    "\n",
    "    # Add REPORT_* columns in uppercase\n",
    "    df = df.withColumn('REPORT_WEEK', F.weekofyear(F.col(app_config[\"general_inputs\"]['date_var'].upper()))) \\\n",
    "           .withColumn('REPORT_MONTH', F.month(F.col(app_config[\"general_inputs\"]['date_var'].upper()))) \\\n",
    "           .withColumn('REPORT_QUARTER', F.quarter(F.col(app_config[\"general_inputs\"]['date_var'].upper()))) \\\n",
    "           .withColumn('REPORT_YEAR', F.year(F.col(app_config[\"general_inputs\"]['date_var'].upper())))\n",
    "\n",
    "    # Extract list of years\n",
    "    years_list = [row['REPORT_YEAR'] for row in df.select('REPORT_YEAR').distinct().collect()]\n",
    "\n",
    "    # Build naming prefix\n",
    "    naming = \"_\".join(coln)\n",
    "\n",
    "    all_years_si = None\n",
    "\n",
    "    # Loop through years\n",
    "    for year in years_list:\n",
    "\n",
    "        year_df = df.filter(F.col('REPORT_YEAR') == year)\n",
    "\n",
    "        ADS_categ = year_df.groupBy(coln + ['REPORT_MONTH', 'REPORT_QUARTER', 'REPORT_WEEK']) \\\n",
    "                           .agg(F.sum(F.col(si_target_column.upper())).alias(quantity_var))\n",
    "\n",
    "        # ------------ MONTHLY SI ----------------\n",
    "        if granularity == 'month':\n",
    "\n",
    "            ADS_categ_monthly_avg = ADS_categ.groupBy(coln + ['REPORT_MONTH']) \\\n",
    "                                             .agg(F.mean(quantity_var).alias('MONTH_AVG'))\n",
    "\n",
    "            si_df = ADS_categ_monthly_avg.join(\n",
    "                        ADS_categ.groupBy(coln).agg(F.mean(quantity_var).alias('YEAR_AVG')),\n",
    "                        on=coln, how='inner'\n",
    "                   ).withColumn(f\"{naming}_SI_MONTHLY\", F.col(\"MONTH_AVG\") / F.col(\"YEAR_AVG\"))\n",
    "\n",
    "            si_cols = ['REPORT_MONTH']\n",
    "            si_value = f\"{naming}_SI_MONTHLY\"\n",
    "\n",
    "        # ------------ QUARTERLY SI ----------------\n",
    "        elif granularity == 'qtr':\n",
    "\n",
    "            ADS_categ_quarterly_avg = ADS_categ.groupBy(coln + ['REPORT_QUARTER']) \\\n",
    "                                               .agg(F.mean(quantity_var).alias('QTR_AVG'))\n",
    "\n",
    "            si_df = ADS_categ_quarterly_avg.join(\n",
    "                        ADS_categ.groupBy(coln).agg(F.mean(quantity_var).alias('YEAR_AVG')),\n",
    "                        on=coln, how='inner'\n",
    "                    ).withColumn(f\"{naming}_SI_QUARTERLY\", F.col(\"QTR_AVG\") / F.col(\"YEAR_AVG\"))\n",
    "\n",
    "            si_cols = ['REPORT_QUARTER']\n",
    "            si_value = f\"{naming}_SI_QUARTERLY\"\n",
    "\n",
    "        # ------------ WEEKLY SI (default) ----------------\n",
    "        else:\n",
    "\n",
    "            ADS_categ_week_avg = ADS_categ.groupBy(coln + ['REPORT_WEEK']) \\\n",
    "                                          .agg(F.mean(quantity_var).alias('WEEK_AVG'))\n",
    "\n",
    "            si_df = ADS_categ_week_avg.join(\n",
    "                        ADS_categ.groupBy(coln).agg(F.mean(quantity_var).alias('YEAR_AVG')),\n",
    "                        on=coln, how='inner'\n",
    "                    ).withColumn(f\"{naming}_SI_WEEKLY\", F.col(\"WEEK_AVG\") / F.col(\"YEAR_AVG\"))\n",
    "\n",
    "            si_cols = ['REPORT_WEEK']\n",
    "            si_value = f\"{naming}_SI_WEEKLY\"\n",
    "\n",
    "        # Append\n",
    "        if all_years_si is None:\n",
    "            all_years_si = si_df\n",
    "        else:\n",
    "            all_years_si = all_years_si.union(si_df)\n",
    "\n",
    "    # Average SI across years\n",
    "    avg_si = all_years_si.groupBy(coln + si_cols).agg(F.mean(si_value).alias(si_value))\n",
    "\n",
    "    # Join back to main DF\n",
    "    si_df = df.join(avg_si, on=coln + si_cols, how='left')\n",
    "\n",
    "    return si_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "id": "ce110000-1111-2222-3333-ffffff000087",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4be08d60-602a-4eed-9b2c-5372a8993954",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "codeCollapsed": false,
    "language": "python",
    "name": "cell88"
   },
   "outputs": [],
   "source": [
    "if si_needed:\n",
    "    for cat in categorical_columns_ads:\n",
    "        if isinstance(cat,list):\n",
    "            cat_ls = cat\n",
    "            cat = \"_\".join(cat_ls)\n",
    "        elif isinstance(cat,str):\n",
    "            cat_ls = [cat]\n",
    "\n",
    "        print(cat,\"level SI creation process started...\")\n",
    "        # create si_weekly\n",
    "        globals()[f\"si_week_{cat}\"] = create_seasonality_index(feature_engineering_output, coln=cat_ls, si_target_column = si_target_column, granularity=None)\n",
    "        globals()[f\"si_week_{cat}\"] = globals()[f\"si_week_{cat}\"].select(app_config[\"general_inputs\"]['date_var'], *modeling_granularity, f\"{cat}_si_weekly\")\n",
    "\n",
    "        # #joining the si\n",
    "        print(f\"\\t===> weekly level SI generated...\")\n",
    "\n",
    "\n",
    "        # create si_monthly\n",
    "        globals()[f\"si_month_{cat}\"] = create_seasonality_index(feature_engineering_output, coln=cat_ls, si_target_column = si_target_column, granularity='month')\n",
    "        globals()[f\"si_month_{cat}\"] = globals()[f\"si_month_{cat}\"].select(app_config[\"general_inputs\"]['date_var'], *modeling_granularity, f\"{cat}_si_monthly\")\n",
    "        print(f\"\\t===> monthly level SI generated...\")\n",
    "\n",
    "\n",
    "        # Create si_qtrly\n",
    "        globals()[f\"si_qtr_{cat}\"] = create_seasonality_index(feature_engineering_output, coln=cat_ls, si_target_column = si_target_column,granularity='qtr')\n",
    "        globals()[f\"si_qtr_{cat}\"] = globals()[f\"si_qtr_{cat}\"].select(app_config[\"general_inputs\"]['date_var'], *modeling_granularity, f\"{cat}_si_quarterly\")\n",
    "\n",
    "        # #joining the si\n",
    "        print(f\"\\t===> quaterly level SI generated...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce110000-1111-2222-3333-ffffff000089",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8d15af81-3696-410d-8ab6-fba647919785",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "name": "cell90"
   },
   "source": [
    "### 1.5. Merging back with granular results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "id": "ce110000-1111-2222-3333-ffffff000090",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "60f80599-77b4-4436-951b-e544cddc2b06",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "language": "python",
    "name": "cell91"
   },
   "outputs": [],
   "source": [
    "if si_needed:\n",
    "    for cat in categorical_columns_ads:\n",
    "        if isinstance(cat,list):\n",
    "            cat_ls = cat\n",
    "            cat = \"_\".join(cat_ls)\n",
    "        elif isinstance(cat,str):\n",
    "            cat_ls = [cat]\n",
    "\n",
    "        print(f\"Integrating {cat} level SI data to granular outputs\")\n",
    "        \n",
    "\n",
    "        # Dropping duplicates (if any) before the merge operation\n",
    "        globals()[f\"si_week_{cat}\"] = globals()[f\"si_week_{cat}\"].dropDuplicates()\n",
    "        globals()[f\"si_month_{cat}\"] = globals()[f\"si_month_{cat}\"].dropDuplicates()\n",
    "        globals()[f\"si_qtr_{cat}\"] = globals()[f\"si_qtr_{cat}\"].dropDuplicates()\n",
    "\n",
    "        # create si_weekly\n",
    "        #joining the si\n",
    "        feature_engineering_output = feature_engineering_output.join(globals()[f\"si_week_{cat}\"], on = [app_config[\"general_inputs\"][\"date_var\"], *modeling_granularity],how = \"left\")\n",
    "        print(f\"\\t===>Joining weekly SI data\")\n",
    "\n",
    "\n",
    "        # create si_monthly\n",
    "        #joining the si\n",
    "        feature_engineering_output = feature_engineering_output.join(globals()[f\"si_month_{cat}\"],on = [app_config[\"general_inputs\"][\"date_var\"], *modeling_granularity],how = \"left\")\n",
    "        print(f\"\\t===>Joining monthly SI data\")\n",
    "\n",
    "\n",
    "        # # Create si_qtrly\n",
    "        # #joining the si\n",
    "        feature_engineering_output = feature_engineering_output.join(globals()[f\"si_qtr_{cat}\"],on = [app_config[\"general_inputs\"][\"date_var\"], *modeling_granularity],how = \"left\")\n",
    "        print(f\"\\t===>Joining quarterly SI data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf0ab40-fd78-42f4-85dd-d1a12b8d2d32",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "cell119"
   },
   "outputs": [],
   "source": [
    "feature_engineering_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a291d212-bdac-419d-8c66-f172a115d901",
   "metadata": {
    "name": "cell129"
   },
   "source": [
    "## Generating trend variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc16557-dc09-41ca-b4b0-e298856daa01",
   "metadata": {
    "language": "python",
    "name": "cell128"
   },
   "outputs": [],
   "source": [
    "feature_engineering_output = (\n",
    "    feature_engineering_output\n",
    "    .with_columns([\"report_week\",\"report_month\",\"report_quarter\",\"report_year\"],[F.weekofyear(F.col(date_col)),F.month(F.col(date_col)),F.quarter(F.col(date_col)),F.year(F.col(date_col))]\n",
    "        \n",
    "    )\n",
    ")\n",
    "\n",
    "def add_linear_trend(df, coln: list, granularity: str):\n",
    "    \"\"\"\n",
    "    Add a linear trend column to the DataFrame based on the specified granularity.\n",
    "\n",
    "    Args:\n",
    "        df: Input DataFrame\n",
    "        coln: List of column names to group by (e.g., ['year', 'month'])\n",
    "        granularity: One of ['month', 'quarter', 'year']\n",
    "\n",
    "    Returns:\n",
    "        DataFrame with trend column added\n",
    "    \"\"\"\n",
    "    valid_granularities = {'month', 'quarter', 'year'}\n",
    "    if granularity not in valid_granularities:\n",
    "        raise ValueError(f\"Invalid granularity: {granularity}. Must be one of {valid_granularities}\")\n",
    "\n",
    "    trend_col_name = f\"trend_{granularity}\"\n",
    "    \n",
    "    trend_df = df.select(*coln).distinct()\n",
    "    trend_df = trend_df.withColumn(trend_col_name, F.row_number().over(Window.orderBy(coln)))\n",
    "    \n",
    "    df = df.join(trend_df, on=coln, how='left')\n",
    "    return df\n",
    "\n",
    "# Add monthly trend column\n",
    "feature_engineering_output = add_linear_trend(feature_engineering_output, coln=['report_year', 'report_month'], granularity='month')\n",
    "\n",
    "# Add quarterly trend column\n",
    "feature_engineering_output = add_linear_trend(feature_engineering_output, coln=['report_year', 'report_quarter'], granularity='quarter')\n",
    "\n",
    "# Add yearly trend column\n",
    "feature_engineering_output = add_linear_trend(feature_engineering_output, coln=['report_year'], granularity='year')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dbab8aa-d11f-41a9-87d7-696061d616fd",
   "metadata": {
    "language": "python",
    "name": "cell130"
   },
   "outputs": [],
   "source": [
    "feature_engineering_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e893d5be-07ef-40aa-9820-c00bff47cdea",
   "metadata": {
    "language": "python",
    "name": "cell47"
   },
   "outputs": [],
   "source": [
    "print(\"Feature Engineering output -> SHAPE\")\n",
    "print(\"Number of rows --->\",feature_engineering_output.count())\n",
    "print(\"Number of columns --->\",len(feature_engineering_output.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4bc0c00-ce7b-47e1-86a7-ae8dfffa3ac4",
   "metadata": {
    "language": "python",
    "name": "cell106"
   },
   "outputs": [],
   "source": [
    "# # write_file(pos, algo_path, \"/Pos_standardization_results (\")\n",
    "results_s_with_ts = feature_engineering_output.with_column(\"LOAD_TS\", F.current_timestamp())\n",
    "results_s_with_ts.write.mode(\"overwrite\").save_as_table(output_table_name)\n",
    "print(results_s_with_ts.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a43ee54-8d82-44b2-8a2d-f3a0498d9fff",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "cell124"
   },
   "outputs": [],
   "source": [
    "test_df = session.table(output_table_name)\n",
    "print(\"All data ->\", test_df.count())\n",
    "latest_ts = test_df.select(F.max(\"LOAD_TS\")).collect()[0][0]\n",
    "feature_engineering_output = test_df.filter(F.col(\"LOAD_TS\") == F.lit(latest_ts))\n",
    "print(\"Latest data ->\", feature_engineering_output.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc02907-b460-4e06-83e0-136d0afefd23",
   "metadata": {
    "collapsed": false,
    "name": "cell21"
   },
   "source": [
    "# Trend and SI features for Future Periods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7ffa9c-2d7f-4253-9730-3b9ffe419f5a",
   "metadata": {
    "collapsed": false,
    "name": "cell46"
   },
   "source": [
    "## Trend features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3a74e9-14c8-4d28-9d98-717fddb84a1c",
   "metadata": {
    "language": "python",
    "name": "cell25"
   },
   "outputs": [],
   "source": [
    "from snowflake.snowpark import functions as F\n",
    "\n",
    "from snowflake.snowpark.functions import col, current_date, dateadd, lit\n",
    "\n",
    "future_periods = int(app_config[\"future_forecast\"][\"no_of_future_periods\"])\n",
    "\n",
    "df_hist = (\n",
    "    feature_engineering_output\n",
    "    .filter(F.col(\"START_OF_WEEK\") <= F.dateadd(\"day\", F.lit(-7), F.current_date()))\n",
    ")\n",
    "\n",
    "# 1. Get max START_OF_WEEK\n",
    "max_week_df = df_hist.select(F.max(\"START_OF_WEEK\").alias(\"max_week\"))\n",
    "max_week = max_week_df.collect()[0][\"MAX_WEEK\"]\n",
    "\n",
    "# 2. Create next 5 weeks\n",
    "future_weeks = (\n",
    "    df_hist.session\n",
    "      .range(1, future_periods+1)  # generates 1..5\n",
    "      .select(\n",
    "          F.dateadd(\"week\", F.col(\"ID\"), F.lit(max_week)).alias(\"START_OF_WEEK\")\n",
    "      )\n",
    ")\n",
    "\n",
    "# 3. Append to original dataframe\n",
    "future_df = df_hist.select(\"START_OF_WEEK\").union_by_name(future_weeks)\n",
    "future_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd22358-e6d5-464e-80a0-33f1ecd00a2d",
   "metadata": {
    "language": "python",
    "name": "cell26"
   },
   "outputs": [],
   "source": [
    "future_df = (\n",
    "    future_df\n",
    "    .with_columns([\"report_week\",\"report_month\",\"report_quarter\",\"report_year\"],[F.weekofyear(F.col(date_col)),F.month(F.col(date_col)),F.quarter(F.col(date_col)),F.year(F.col(date_col))]\n",
    "        \n",
    "    )\n",
    ")\n",
    "future_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b91e1d-5bca-4f7c-9611-5083a794e5c2",
   "metadata": {
    "language": "python",
    "name": "cell27"
   },
   "outputs": [],
   "source": [
    "# Add monthly trend column\n",
    "future_df = add_linear_trend(future_df, coln=['report_year', 'report_month'], granularity='month')\n",
    "\n",
    "# Add quarterly trend column\n",
    "future_df = add_linear_trend(future_df, coln=['report_year', 'report_quarter'], granularity='quarter')\n",
    "\n",
    "# Add yearly trend column\n",
    "future_df = add_linear_trend(future_df, coln=['report_year'], granularity='year')\n",
    "future_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6cc986-9ad5-4669-a6a7-6bb714506cda",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "cell28"
   },
   "outputs": [],
   "source": [
    "results_s_with_ts = future_df.with_column(\"LOAD_TS\", F.current_timestamp())\n",
    "results_s_with_ts.write.mode(\"overwrite\").save_as_table(\"TRENDS_FUTURE_DATA\")\n",
    "print(results_s_with_ts.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef060ae8-c11e-40bf-bfc3-630e06a4ff59",
   "metadata": {
    "collapsed": false,
    "name": "cell45"
   },
   "source": [
    "## SI features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d429519e-d876-4435-aec8-fcf60569cec7",
   "metadata": {
    "language": "python",
    "name": "cell29"
   },
   "outputs": [],
   "source": [
    "#weekly_si = create_seasonality_index(feature_engineering_output, coln=cat_ls, si_target_column = si_target_column, granularity=None)\n",
    "weekly_si = feature_engineering_output.select([\"REGIONNAME\",\"REPORT_WEEK\",\"REGIONNAME_SI_WEEKLY\"]).dropDuplicates()\n",
    "weekly_si"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95571541-a2bb-4b18-a735-442a8b94cbfd",
   "metadata": {
    "language": "python",
    "name": "cell30"
   },
   "outputs": [],
   "source": [
    "results_s_with_ts = weekly_si.with_column(\"LOAD_TS\", F.current_timestamp())\n",
    "results_s_with_ts.write.mode(\"overwrite\").save_as_table(\"SI_FUTURE_DATA\")\n",
    "print(results_s_with_ts.count())"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "2.1. Feature Engineering ( mbp_tpr) Modified",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  },
  "lastEditStatus": {
   "authorEmail": "harish.sundarara@purposebrands.com",
   "authorId": "6771236268325",
   "authorName": "HSUNDARARAJAN",
   "lastEditTime": 1766500006324,
   "notebookId": "twqgi2gfkj6ep67fwjfp",
   "sessionId": "d3afc54b-674a-4899-a64c-15348bd3fce0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
